{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Objetivo\n",
    "Crear y evaluar un modelo de arboles aleatotios (random forest) para predecir las ventas con datos simulados de una empresa dependiendo de las inversiones realizadas en publicidad.\n",
    "\n",
    "# 2 Descripción\n",
    "- Se utiliza programación Python\n",
    "- Cargar librerías y datos\n",
    "- Limpiar datos si es necesario\n",
    "- Explorar datos\n",
    "- Partir los datos en datos de entrenamiento y datos de validación 70% y 30%\n",
    "- Crear modelo de regresión con los datos de entrenamiento\n",
    "- Predicciones\n",
    "- Evaluar predicciones con respecto a datos reales\n",
    "- Determinar el estadístico rmse para evaluar con respecto a otros modelos\n",
    "- Interpretar el caso\n",
    "\n",
    "# 3 Fundamento teórico\n",
    "Extraído de : (Amat Rodrigo 2017)\n",
    "\n",
    "Un modelo Random Forest está formado por un conjunto (ensemble) de árboles de decisión individuales, cada uno entrenado con una muestra aleatoria extraída de los datos de entrenamiento originales mediante bootstrapping. Esto implica que cada árbol se entrena con unos datos ligeramente distintos.\n",
    "\n",
    "En cada árbol individual, las observaciones se van distribuyendo por bifurcaciones (nodos) generando la estructura del árbol hasta alcanzar un nodo terminal. La predicción de una nueva observación se obtiene agregando las predicciones de todos los árboles individuales que forman el modelo.\n",
    "\n",
    "Para entender cómo funcionan los modelos Random Forest es necesario conocer primero los conceptos de ensemble y bagging.\n",
    "\n",
    "Métodos de ensemble\n",
    "\n",
    "Todos los modelos de aprendizaje estadístico y machine learning sufren el problema de equilibrio entre bias y varianza.\n",
    "\n",
    "El término bias (sesgo) hace referencia a cuánto se alejan en promedio las predicciones de un modelo respecto a los valores reales. Refleja cómo de capaz es el modelo de aprender la relación real que existe entre los predictores y la variable respuesta. Por ejemplo, si la relación sigue un patrón no lineal, por muchos datos de los que se disponga, un modelo de regresión lineal no podrá modelar correctamente la relación, por lo que tendrá un bias alto.\n",
    "\n",
    "El término varianza hace referencia a cuánto cambia el modelo dependiendo de los datos utilizados en su entrenamiento. Idealmente, un modelo no debería modificarse demasiado por pequeñas variaciones en los datos de entrenamiento, si esto ocurre, es porque el modelo está memorizando los datos en lugar de aprender la verdadera relación entre los predictores y la variable respuesta. Por ejemplo, un modelo de árbol con muchos nodos, suele variar su estructura con que apenas cambien unos pocos datos de entrenamiento, tiene mucha varianza.\n",
    "\n",
    "A medida que aumenta la complejidad de un modelo, este dispone de mayor flexibilidad para adaptarse a las observaciones, reduciendo así el bias y mejorando su capacidad predictiva. Sin embargo, alcanzado un determinado grado de flexibilidad, aparece el problema de overfitting, el modelo se ajusta tanto a los datos de entrenamiento que es incapaz de predecir correctamente nuevas observaciones. El mejor modelo es aquel que consigue un equilibrio óptimo entre bias y varianza.\n",
    "\n",
    "¿Cómo se controlan el bias y varianza en los modelos basados en árboles? Por lo general, los árboles pequeños (pocas ramificaciones) tienen poca varianza pero no consiguen representar bien la relación entre las variables, es decir, tienen bias alto. En contraposición, los árboles grandes se ajustan mucho a los datos de entrenamiento, por lo que tienen muy poco bias pero mucha varianza. Una forma de solucionar este problema son los métodos de ensemble.\n",
    "\n",
    "Los métodos de ensemble combinan múltiples modelos en uno nuevo con el objetivo de lograr un equilibro entre bias y varianza, consiguiendo así mejores predicciones que cualquiera de los modelos individuales originales. Dos de los tipos de ensemble más utilizados son:\n",
    "\n",
    "Bagging: Se ajustan múltiples modelos, cada uno con un subconjunto distinto de los datos de entrenamiento. Para predecir, todos los modelos que forman el agregado participan aportando su predicción. Como valor final, se toma la media de todas las predicciones (variables continuas) o la clase más frecuente (variables categóricas). Los modelos Random Forest están dentro de esta categoría.\n",
    "\n",
    "Boosting: Se ajustan secuencialmente múltiples modelos sencillos, llamados weak learners, de forma que cada modelo aprende de los errores del anterior. Como valor final, al igual que en bagging, se toma la media de todas las predicciones (variables continuas) o la clase más frecuente (variables cualitativas). Tres de los métodos de boosting más empleados son AdaBoost, Gradient Boosting y Stochastic Gradient Boosting.\n",
    "\n",
    "Aunque el objetivo final es el mismo, lograr un balance óptimo entre bias y varianza, existen dos diferencias importantes:\n",
    "\n",
    "Forma en que consiguen reducir el error total. El error total de un modelo puede descomponerse como bias+varianza+ϵ.\n",
    "\n",
    "En bagging, se emplean modelos con muy poco bias pero mucha varianza, agregándolos se consigue reducir la varianza sin apenas inflar el bias. En boosting, se emplean modelos con muy poca varianza pero mucho bias, ajustando secuencialmente los modelos se reduce el bias. Por lo tanto, cada una de las estrategias reduce una parte del error total.\n",
    "\n",
    "Forma en que se introducen variaciones en los modelos que forman el ensemble. En bagging, cada modelo es distinto del resto porque cada uno se entrena con una muestra distinta obtenida mediante bootstrapping. En boosting, los modelos se ajustan secuencialmente y la importancia (peso) de las observaciones va cambiando en cada iteración, dando lugar a diferentes ajustes.\n",
    "\n",
    "La clave para que los métodos de ensemble consigan mejores resultados que cualquiera de sus modelos individuales es que, los modelos que los forman, sean lo más diversos posibles (sus errores no estén correlacionados). Una analogía que refleja este concepto es la siguiente: supóngase un juego como el trivial en el que los equipos tienen que acertar preguntas sobre temáticas diversas. Un equipo formado por muchos jugadores, cada uno experto en un tema distinto, tendrá más posibilidades de ganar que un equipo formado por jugadores expertos en un único tema o por un único jugador que sepa un poco de todos los temas.\n",
    "\n",
    "A continuación, se describe con más detalle la estrategia de bagging, sobre la que se fundamenta el modelo Random Forest.\n",
    "\n",
    "Bagging\n",
    "\n",
    "El término bagging es el diminutivo de bootstrap aggregation, y hace referencia al empleo del muestreo repetido con reposición bootstrapping con el fin de reducir la varianza de algunos modelos de aprendizaje estadístico, entre ellos los basados en árboles.\n",
    "\n",
    "Dadas n muestras de observaciones independientes Z1,...Zn, cada una con varianza σ2, la varianza de la media de las observaciones Z¯ es σ2/n.\n",
    "\n",
    "En otras palabras, promediando un conjunto de observaciones se reduce la varianza.\n",
    "\n",
    "Basándose en esta idea, una forma de reducir la varianza y aumentar la precisión de un método predictivo es obtener múltiples muestras de la población, ajustar un modelo distinto con cada una de ellas, y hacer la media (la moda en el caso de variables cualitativas) de las predicciones resultantes.\n",
    "\n",
    "Como en la práctica no se suele tener acceso a múltiples muestras, se puede simular el proceso recurriendo a bootstrapping, generando así pseudo-muestras con los que ajustar diferentes modelos y después agregarlos. A este proceso se le conoce como bagging y es aplicable a una gran variedad de métodos de regresión.\n",
    "\n",
    "En el caso particular de los árboles de decisión, dada su naturaleza de bajo bias y alta varianza, bagging ha demostrado tener muy buenos resultados. La forma de aplicarlo es:\n",
    "\n",
    "Generar BB pseudo-training sets mediante bootstrapping a partir de la muestra de entrenamiento original.\n",
    "\n",
    "Entrenar un árbol con cada una de las BB muestras del paso\n",
    "\n",
    "Cada árbol se crea sin apenas restricciones y no se somete a pruning, por lo que tiene varianza alta pero poco bias. En la mayoría de casos, la única regla de parada es el número mínimo de observaciones que deben tener los nodos terminales. El valor óptimo de este hiperparámetro puede obtenerse comparando el out of bag error o por validación cruzada.\n",
    "\n",
    "Para cada nueva observación, obtener la predicción de cada uno de los BB árboles. El valor final de la predicción se obtiene como la media de las BB predicciones en el caso de variables cuantitativas y como la clase predicha más frecuente (moda) para variables cualitativas.\n",
    "\n",
    "En el proceso de bagging, el número de árboles creados no es un hiperparámetro crítico en cuanto a que, por mucho que se incremente el número, no se aumenta el riesgo de overfitting. Alcanzado un determinado número de árboles, la reducción de test error se estabiliza. A pesar de ello, cada árbol ocupa memoria, por lo que no conviene almacenar más de los necesarios.\n",
    "\n",
    "Entrenamiento de Random Forest\n",
    "\n",
    "El algoritmo de Random Forest es una modificación del proceso de bagging que consigue mejorar los resultados gracias a que decorrelaciona aún más los árboles generados en el proceso.\n",
    "\n",
    "Recordando el apartado anterior, los beneficios del bagging se basan en el hecho de que, promediando un conjunto de modelos, se consigue reducir la varianza. Esto es cierto siempre y cuando los modelos agregados no estén correlacionados. Si la correlación es alta, la reducción de varianza que se puede lograr es pequeña.\n",
    "\n",
    "Suponendo un set de datos en el que hay un predictor muy influyente, junto con otros moderadamente influyentes. En este escenario, todos o casi todos los árboles creados en el proceso de bagging estarán dominados por el mismo predictor y serán muy parecidos entre ellos. Como consecuencia de la alta correlación entre los árboles, el proceso de bagging apenas conseguirá disminuir la varianza y, por lo tanto, tampoco mejorar el modelo.\n",
    "\n",
    "Random forest evita este problema haciendo una selección aleatoria de mm predictores antes de evaluar cada división. De esta forma, un promedio de (p−m)/p divisiones no contemplarán el predictor influyente, permitiendo que otros predictores puedan ser seleccionados. Añadiendo este paso extra se consigue decorrelacionar los árboles todavía más, con lo que su agregación consigue una mayor reducción de la varianza.\n",
    "\n",
    "Los métodos de random forest y bagging siguen el mismo algoritmo con la única diferencia de que, en random forest, antes de cada división, se seleccionan aleatoriamente m predictores. La diferencia en el resultado dependerá del valor m escogido. Si m=p los resultados de random forest y bagging son equivalentes. Algunas recomendaciones son:\n",
    "\n",
    "La raíz cuadrada del número total de predictores para problemas de clasificación. m≈p–√\n",
    "\n",
    "Un tercio del número de predictores para problemas de regresión m≈p3.\n",
    "\n",
    "Si los predictores están muy correlacionados, valores pequeños de m consiguen mejores resultados.\n",
    "\n",
    "Sin embargo, la mejor forma para encontrar el valor óptimo de mm es evaluar el out-of-bag-error o recurrir a validación cruzada.\n",
    "\n",
    "Al igual que ocurre con bagging, random forest no sufre problemas de overfit por aumentar el número de árboles creados en el proceso. Alcanzado un determinado número, la reducción del error de test se estabiliza.\n",
    "\n",
    "Por otra parte como lo menciona mejor formar de evaluar los datos podría ser utilizar diversos arboles de decisión, así hacer una mejor predicción calculando el promedio de sus predicciones, este enfoque se denomina como algoritmos de ensamble o ensemble learning.\n",
    "\n",
    "De este algoritmo se pudiera decir, que une multiples arboles de decision, así crea un bosque de predicción, las evalúa y entrega el resultado promedio. (Veloso 2019)\n",
    "\n",
    "# 4 Desarrollo\n",
    "Para trabajar con código Python, se deben cargan las librerías de Python previamente instaladas con la función py_install() de la librería reticulate de R.\n",
    "\n",
    "La función repl_python() se utilizar para ejecutar ventana de comando o shell de Python.\n",
    "\n",
    "Se recomienda instalar estos paquetes de Python\n",
    "\n",
    "- py_install(packages = “pandas”)\n",
    "- py_install(packages = “matplotlib”)\n",
    "- py_install(packages = “numpy”)\n",
    "- py_install(packages = “sklearn”) en R cloud\n",
    "- py_install(“scikit-learn”) R Studio local\n",
    "- py_install(packages = “statsmodels.api”)\n",
    "- py_install(packages = “seaborn”)\n",
    "\n",
    "En terminal de Python se puede actualizar con conda create -n py3.8 python=3.8 scikit-learn pandas numpy matplotlib\n",
    "\n",
    "## 4.1 Cargar librerías\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "# Preprocesado y moYdelado\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.tree import plot_tree\n",
    "# from sklearn.tree import export_graphviz\n",
    "# from sklearn.tree import export_text\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X</th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Web</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>306.634752</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>302.653070</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>49.498908</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>257.816893</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>195.660076</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>196</td>\n",
       "      <td>38.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>248.841073</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>94.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>118.041856</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>177.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>213.274671</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>283.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>237.498063</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>232.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>151.990733</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0    X     TV  Radio  Newspaper         Web  Sales\n",
       "0             1    1  230.1   37.8       69.2  306.634752   22.1\n",
       "1             2    2   44.5   39.3       45.1  302.653070   10.4\n",
       "2             3    3   17.2   45.9       69.3   49.498908    9.3\n",
       "3             4    4  151.5   41.3       58.5  257.816893   18.5\n",
       "4             5    5  180.8   10.8       58.4  195.660076   12.9\n",
       "..          ...  ...    ...    ...        ...         ...    ...\n",
       "195         196  196   38.2    3.7       13.8  248.841073    7.6\n",
       "196         197  197   94.2    4.9        8.1  118.041856    9.7\n",
       "197         198  198  177.0    9.3        6.4  213.274671   12.8\n",
       "198         199  199  283.6   42.0       66.2  237.498063   25.5\n",
       "199         200  200  232.1    8.6        8.7  151.990733   13.4\n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = pd.read_csv(\"https://raw.githubusercontent.com/rpizarrog/Analisis-Inteligente-de-datos/main/datos/Advertising_Web.csv\")\n",
    "datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Explorar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observaciones y variables:  (200, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Observaciones y variables: \", datos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas y tipo de dato\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'X', 'TV', 'Radio', 'Newspaper', 'Web', 'Sales'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Columnas y tipo de dato\")\n",
    "datos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      int64\n",
       "X               int64\n",
       "TV            float64\n",
       "Radio         float64\n",
       "Newspaper     float64\n",
       "Web           float64\n",
       "Sales         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  200 non-null    int64  \n",
      " 1   X           200 non-null    int64  \n",
      " 2   TV          200 non-null    float64\n",
      " 3   Radio       200 non-null    float64\n",
      " 4   Newspaper   200 non-null    float64\n",
      " 5   Web         200 non-null    float64\n",
      " 6   Sales       200 non-null    float64\n",
      "dtypes: float64(5), int64(2)\n",
      "memory usage: 11.1 KB\n"
     ]
    }
   ],
   "source": [
    "datos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se describen las variables independientes: TV, Radio Newpaper y la variable dependiente Sales.\n",
    "\n",
    "Valor de etiqueta o variable objetivo deendiente(ventas): que significa el volumen de ventas del producto correspondiente\n",
    "\n",
    "Las variables independientes: (TV, Radio, Periódico, WEB):\n",
    "\n",
    "- TV: son los costos de la publicidad en TV (en miles)\n",
    "- Radio: costos de publicidad invertidos en medios de difusión radio;\n",
    "- Newspaper Periódico: costos publicitarios para medios impresos.\n",
    "- Web: Costos de publicidad invertidos en herramientas digitales.\n",
    "\n",
    "## 4.4 Limpiar datos\n",
    "Quitar las primeras columnas y dejar TV Radio NewsPaper Web y Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Web</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>159.587355</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>76.815266</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>4.308085</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>99.048767</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>156.862154</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>212.311848</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>358.247042</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TV       Radio   Newspaper         Web       Sales\n",
       "count  200.000000  200.000000  200.000000  200.000000  200.000000\n",
       "mean   147.042500   23.264000   30.554000  159.587355   14.022500\n",
       "std     85.854236   14.846809   21.778621   76.815266    5.217457\n",
       "min      0.700000    0.000000    0.300000    4.308085    1.600000\n",
       "25%     74.375000    9.975000   12.750000   99.048767   10.375000\n",
       "50%    149.750000   22.900000   25.750000  156.862154   12.900000\n",
       "75%    218.825000   36.525000   45.100000  212.311848   17.400000\n",
       "max    296.400000   49.600000  114.000000  358.247042   27.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = datos[['TV','Radio', 'Newspaper', 'Web', 'Sales']]\n",
    "datos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Web</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>306.634752</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>302.653070</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>49.498908</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>257.816893</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>195.660076</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>38.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>248.841073</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>94.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>118.041856</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>177.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>213.274671</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>283.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>237.498063</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>232.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>151.990733</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  Radio  Newspaper         Web  Sales\n",
       "0    230.1   37.8       69.2  306.634752   22.1\n",
       "1     44.5   39.3       45.1  302.653070   10.4\n",
       "2     17.2   45.9       69.3   49.498908    9.3\n",
       "3    151.5   41.3       58.5  257.816893   18.5\n",
       "4    180.8   10.8       58.4  195.660076   12.9\n",
       "..     ...    ...        ...         ...    ...\n",
       "195   38.2    3.7       13.8  248.841073    7.6\n",
       "196   94.2    4.9        8.1  118.041856    9.7\n",
       "197  177.0    9.3        6.4  213.274671   12.8\n",
       "198  283.6   42.0       66.2  237.498063   25.5\n",
       "199  232.1    8.6        8.7  151.990733   13.4\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Datos de entrenamiento y datos de validación\n",
    "Se utiliza semilla 1550 (random_state=1550)\n",
    "\n",
    "La función train_test_split() parte los datos originales el 70% y 30% para datos de entrenamiento y validación y con el argumento datos.drop(columns = “Sales”), datos[‘Sales’] solo incluye las variables independientes; la semilla de aleatoriedad es 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_entrena, X_valida, Y_entrena, Y_valida = train_test_split(datos.drop(columns = \"Sales\"), datos['Sales'],train_size=.70,  random_state=1550)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 Datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estructura de datos de entrenamiento...  (140, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Estructura de datos de entrenamiento... \", X_entrena.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TV  Radio  Newspaper         Web\n",
      "53   182.6   46.2       58.7  176.050052\n",
      "145  140.3    1.9        9.0  231.883385\n",
      "54   262.7   28.8       15.9  324.615179\n",
      "90   134.3    4.9        9.3  258.355488\n",
      "52   216.4   41.7       39.6  161.802512\n",
      "..     ...    ...        ...         ...\n",
      "15   195.4   47.7       52.9  148.095134\n",
      "181  218.5    5.4       27.4  162.387486\n",
      "137  273.7   28.9       59.7  288.260611\n",
      "25   262.9    3.5       19.5  160.562859\n",
      "74   213.4   24.6       13.1  156.284261\n",
      "\n",
      "[140 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_entrena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TV\n",
      "53   182.6\n",
      "145  140.3\n",
      "54   262.7\n",
      "90   134.3\n",
      "52   216.4\n",
      "..     ...\n",
      "15   195.4\n",
      "181  218.5\n",
      "137  273.7\n",
      "25   262.9\n",
      "74   213.4\n",
      "\n",
      "[140 rows x 1 columns]      Radio\n",
      "53    46.2\n",
      "145    1.9\n",
      "54    28.8\n",
      "90     4.9\n",
      "52    41.7\n",
      "..     ...\n",
      "15    47.7\n",
      "181    5.4\n",
      "137   28.9\n",
      "25     3.5\n",
      "74    24.6\n",
      "\n",
      "[140 rows x 1 columns]      Newspaper\n",
      "53        58.7\n",
      "145        9.0\n",
      "54        15.9\n",
      "90         9.3\n",
      "52        39.6\n",
      "..         ...\n",
      "15        52.9\n",
      "181       27.4\n",
      "137       59.7\n",
      "25        19.5\n",
      "74        13.1\n",
      "\n",
      "[140 rows x 1 columns]             Web\n",
      "53   176.050052\n",
      "145  231.883385\n",
      "54   324.615179\n",
      "90   258.355488\n",
      "52   161.802512\n",
      "..          ...\n",
      "15   148.095134\n",
      "181  162.387486\n",
      "137  288.260611\n",
      "25   160.562859\n",
      "74   156.284261\n",
      "\n",
      "[140 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_entrena[['TV']], X_entrena[['Radio']], X_entrena[['Newspaper']], X_entrena[['Web']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Modelo de Random Forest\n",
    "Se crea el modelo con la función RandomForestRegressor().fit() con los datos de entrenamiento que contiene la variables independientes en relación a la variable dependiente ‘Sales’.\n",
    "\n",
    "El argumento n_estimators define el número de árboles en el bosque aleatorio. Puede usar cualquier valor numérico para el parámetro n_estimator.\n",
    "\n",
    "El valor argumento de random_state es la semilla para la aleatoriedad del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=50, random_state=1550)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=50, random_state=1550)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=50, random_state=1550)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestRegressor(n_estimators = 50, random_state = 1550)\n",
    "\n",
    "model_rf.fit(X_entrena, Y_entrena)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Construir predicciones\n",
    "Se generan predicciones con los datos de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.792,  6.188, 23.48 ,  9.436, 18.672, 20.096, 23.98 , 11.994,\n",
       "       24.922, 19.842, 19.422, 10.752, 10.702, 22.316, 18.132,  6.92 ,\n",
       "        6.978, 19.234, 22.488, 24.   ,  7.38 , 15.614, 13.41 ,  9.922,\n",
       "       15.928, 12.154,  9.676, 13.224, 18.6  , 11.966, 10.704, 21.476,\n",
       "       17.62 , 13.906, 11.376, 12.09 , 15.618, 22.462, 18.912, 11.87 ,\n",
       "       15.384, 13.362, 13.202,  6.566, 11.82 , 13.222, 15.81 ,  9.448,\n",
       "       21.53 ,  5.038, 10.29 , 14.232, 11.008, 17.808,  9.44 , 11.956,\n",
       "        9.63 ,  7.576, 12.832, 10.792])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones = model_rf.predict(X_valida)\n",
    "predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 Construir matriz de comparación\n",
    "Construir una conjunto de datos con los valores reales de los datos de validación y las predicciones generadas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Sales  Predicho\n",
      "155    3.2     4.792\n",
      "5      7.2     6.188\n",
      "17    24.4    23.480\n",
      "107    8.7     9.436\n",
      "28    18.9    18.672\n",
      "176   20.2    20.096\n",
      "61    24.2    23.980\n",
      "81    12.3    11.994\n",
      "183   26.2    24.922\n",
      "141   19.2    19.842\n",
      "133   19.6    19.422\n",
      "18    11.3    10.752\n",
      "157   10.1    10.702\n",
      "55    23.7    22.316\n",
      "41    17.1    18.132\n",
      "192    5.9     6.920\n",
      "189    6.7     6.978\n",
      "142   20.1    19.234\n",
      "58    23.8    22.488\n",
      "198   25.5    24.000\n",
      "91     7.3     7.380\n",
      "154   15.6    15.614\n",
      "37    14.7    13.410\n",
      "65     9.3     9.922\n",
      "45    14.9    15.928\n",
      "146   13.2    12.154\n",
      "32     9.6     9.676\n",
      "114   14.6    13.224\n",
      "153   19.0    18.600\n",
      "151   11.6    11.966\n",
      "6     11.8    10.704\n",
      "139   20.7    21.476\n",
      "105   19.2    17.620\n",
      "179   12.6    13.906\n",
      "144   11.4    11.376\n",
      "100   11.7    12.090\n",
      "19    14.6    15.618\n",
      "111   21.8    22.462\n",
      "109   19.8    18.912\n",
      "174   11.5    11.870\n",
      "171   14.5    15.384\n",
      "7     13.2    13.362\n",
      "31    11.9    13.202\n",
      "22     5.6     6.566\n",
      "131   12.7    11.820\n",
      "116   12.2    13.222\n",
      "123   15.2    15.810\n",
      "117    9.4     9.448\n",
      "39    21.5    21.530\n",
      "132    5.7     5.038\n",
      "125   10.6    10.290\n",
      "4     12.9    14.232\n",
      "73    11.0    11.008\n",
      "194   17.3    17.808\n",
      "10     8.6     9.440\n",
      "35    12.8    11.956\n",
      "129    9.7     9.630\n",
      "106    7.2     7.576\n",
      "164   11.9    12.832\n",
      "140   10.9    10.792\n"
     ]
    }
   ],
   "source": [
    "comparaciones = pd.DataFrame(Y_valida)\n",
    "\n",
    "# comparaciones = comparaciones.assign(Sales_Real = Y_valida)\n",
    "\n",
    "comparaciones = comparaciones.assign(Predicho = predicciones.flatten().tolist())\n",
    "\n",
    "print(comparaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.9 Evaluación del modelo con RMSE\n",
    "Este valor normalmente se compara contra otro modelo y el que esté mas cerca de cero es mejor.\n",
    "\n",
    "La raiz del Error Cuadrático Medio (rmse) es una métrica que dice qué tan lejos están los valores predichos de los valores observados o reales en un análisis de regresión, en promedio. \n",
    "\n",
    "RMSE es una forma útil de ver qué tan bien un modelo de regresión puede ajustarse a un conjunto de datos.\n",
    "\n",
    "Cuanto mayor sea el rmse, mayor será la diferencia entre los valores predichos y reales, lo que significa que peor se ajusta un modelo de regresión a los datos. Por el contrario, cuanto más pequeño sea el rmse, mejor podrá un modelo ajustar los datos.\n",
    "\n",
    "Se compara este valor de rmse con respecto al modelo de regresión múltiple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El error (rmse) de test es: 0.839761791621091\n"
     ]
    }
   ],
   "source": [
    "rmse = mean_squared_error(\n",
    "        y_true  = Y_valida,\n",
    "        y_pred  = predicciones,\n",
    "        squared = False\n",
    "       )\n",
    "print(f\"El error (rmse) de test es: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: MSE 0.7051998666666647\n"
     ]
    }
   ],
   "source": [
    "print('Mean Squared Error: MSE', metrics.mean_squared_error(Y_valida, predicciones))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error RMSE: 0.839761791621091\n"
     ]
    }
   ],
   "source": [
    "print('Root Mean Squared Error RMSE:', np.sqrt(metrics.mean_squared_error(Y_valida, predicciones)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para estos datos para estos valores de entrenamiento y validación, con un valor de 50 árboles en el modelo, el valor de RMSE es aproximadamente 0.7660, menor que el valor de árbol de regresión en Python del Caso 4.\n",
    "\n",
    "El RMSE obtenido se puede comparar contra los estadísticos RMSE de los modelos regresión múltiple y árbol de regresión tanto de Python y de R , se puede interpretar cuál modelo es más eficiente en términos de este estadístico con estos datos.\n",
    "\n",
    "# Interpretación\n",
    "Comparando los valores RMSE obtenidos tanto en RStudio como en Python, concluyo que el modelo de Python es mucho más eficaz que aquel de RStudio, esto debido a que la medida RMSE es mucho menor, siendo esta un ~0.839761791621091, la cual es una buena medida para el RMSE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94a9a47cd63edf064273420544211dc39e24505107daed98145828c8244b81fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
